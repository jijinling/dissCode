{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad7a8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "# import pydicom as pdcm\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "import copy\n",
    "import nibabel as nib \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb5e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list = []\n",
    "for root, dirs, files in os.walk('./AD/'):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        all_list.append(file_path)\n",
    "\n",
    "for root, dirs, files in os.walk('./CN/'):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        all_list.append(file_path)\n",
    "all_list = list(filter(lambda x: '.DS_Store' not in x, all_list))\n",
    "# all_list.remove('./CN/011_S_0016/ADNI_011_S_0016_MR_MPR-R__GradWarp__B1_Correction__N3__Scaled_Br_20061206170814835_S13160_I31928.nii')\n",
    "# all_list.remove('./CN/013_S_0502/ADNI_013_S_0502_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20070926112008188_S27531_I75291.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "274bbeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stdevs = [], []\n",
    "all_data = np.zeros((100, 192, 192, 160))\n",
    "for idx, val in enumerate(all_list):\n",
    "    img = nib.load(val) #读取nii\n",
    "    img_fdata = img.get_fdata()\n",
    "    if img_fdata.shape[2] > 160:\n",
    "        img_fdata = img_fdata[:, :, 4:164]\n",
    "    img_fdata = cv2.resize(img_fdata, (192, 192))\n",
    "    all_data[idx] = img_fdata\n",
    "\n",
    "means = np.mean(all_data, axis = (0, 1, 2))\n",
    "stds = np.std(all_data, axis = (0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e44f192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIdata(Dataset):\n",
    "    def __init__(self, path_list, transform = None):\n",
    "        self.path_list = path_list\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img = nib.load(self.path_list[index]) #读取nii\n",
    "        img_fdata = img.get_fdata()\n",
    "        if img_fdata.shape[2] > 160:\n",
    "            img_fdata = img_fdata[:, :, 4:164]\n",
    "        img_fdata = cv2.resize(img_fdata, (192, 192))\n",
    "        \n",
    "#         print(img_fdata.shape, type(img_fdata))\n",
    "\n",
    "#         inp_data = read_dicom_img(self.train_dir, str(self.data['BraTS21ID'][index]))\n",
    "        inp_data = self.transform(img_fdata[:])\n",
    "        if self.path_list[index].split('/')[1] == 'AD':\n",
    "            label = torch.tensor(1, dtype = torch.float)\n",
    "        else:\n",
    "            label = torch.tensor(0, dtype = torch.float)\n",
    "        \n",
    "#         print(self.path_list[index].split('/')[1])\n",
    "        return inp_data.float(), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189a2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose([T.ToTensor(), T.Normalize(means, stds)])\n",
    "\n",
    "\n",
    "random.shuffle(all_list)\n",
    "\n",
    "train_dataset = MRIdata(all_list[:80], transform = transforms)\n",
    "train_loader = DataLoader(train_dataset, shuffle = True, batch_size = 16)\n",
    "\n",
    "test_dataset = MRIdata(all_list[80:], transform = transforms)\n",
    "test_loader = DataLoader(test_dataset, shuffle = False, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fabae12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for indx, (data, label) in enumerate(train_loader, 0):\n",
    "#     inputs, labels = data.to(device), label.to(device)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a55f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRINet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(self.conv_layer(in_chan = 160, out_chan = 128),\n",
    "                                  self.conv_layer(in_chan = 128, out_chan = 128),\n",
    "                                  self.conv_layer(in_chan = 128, out_chan = 256))\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(123904, 512),\n",
    "                                nn.Dropout(p = 0.15),\n",
    "                                nn.Linear(512, 1))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def conv_layer(self, in_chan, out_chan):\n",
    "        conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_chan, out_chan, kernel_size=(3, 3), padding = 0),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.BatchNorm2d(out_chan))\n",
    "        \n",
    "        return conv_layer    \n",
    "           \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)    \n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd50171f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 1, 3, 3, 3], expected input[1, 16, 160, 192, 192] to have 1 channels, but got 16 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#.squeeze(1)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/shuo/med class/models/cnn.py:44\u001b[0m, in \u001b[0;36mcnn3d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m#print('input shape:', x.shape)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1_bn(x)\n\u001b[1;32m     46\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:607\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:602\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    592\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    593\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    601\u001b[0m     )\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 1, 3, 3, 3], expected input[1, 16, 160, 192, 192] to have 1 channels, but got 16 channels instead"
     ]
    }
   ],
   "source": [
    "net = MRINet().to(device)\n",
    "# net = cnn3d().to(device)\n",
    "LRate = 0.001\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = LRate)\n",
    "EPOCHS = 50\n",
    "best_score = np.inf\n",
    "\n",
    "\n",
    "best_model = copy.deepcopy(net)  # Will work\n",
    "    \n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    count = 0\n",
    "    net.train()\n",
    "    for indx, (data, label) in enumerate(train_loader, 0):\n",
    "        inputs, labels = data.to(device), label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)#.squeeze(1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        total_loss += loss.detach().item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    print(f\"Epoch:{epoch}/{EPOCHS} - train Loss:{total_loss/count}\")\n",
    "    \n",
    "    net.eval()\n",
    "    total_loss = 0.0\n",
    "    count = 0\n",
    "    for indx, (data, label) in enumerate(test_loader, 0):\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = data.to(device), label.to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.detach().item()\n",
    "\n",
    "            count += 1\n",
    "    if best_score > total_loss / count:\n",
    "        print('loss {} -> {} reduce saving ....'.format(best_score, total_loss / count))\n",
    "        best_model = copy.deepcopy(net)  \n",
    "        \n",
    "        best_score = total_loss / count\n",
    "    print(f\"Epoch:{epoch}/{EPOCHS} - test Loss:{total_loss/count}\")\n",
    "    print('-----------------------')\n",
    "\n",
    "print(\"Training Complete\")    \n",
    "torch.save(best_model, './best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a230b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9283fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0/50 - train Loss:22.917480087280275\n",
      "loss inf -> 32.95305633544922 reduce saving ....\n",
      "Epoch:0/50 - test Loss:32.95305633544922\n",
      "-----------------------\n",
      "Epoch:1/50 - train Loss:22.394531631469725\n",
      "Epoch:1/50 - test Loss:32.95305633544922\n",
      "-----------------------\n",
      "Epoch:2/50 - train Loss:21.879074478149413\n",
      "Epoch:2/50 - test Loss:32.95305633544922\n",
      "-----------------------\n",
      "Epoch:3/50 - train Loss:21.754942321777342\n",
      "Epoch:3/50 - test Loss:32.95305633544922\n",
      "-----------------------\n",
      "Epoch:4/50 - train Loss:21.839803886413574\n",
      "Epoch:4/50 - test Loss:32.95305633544922\n",
      "-----------------------\n",
      "Epoch:5/50 - train Loss:21.852628898620605\n",
      "Epoch:5/50 - test Loss:34.46629333496094\n",
      "-----------------------\n",
      "Epoch:6/50 - train Loss:21.869690322875975\n",
      "Epoch:6/50 - test Loss:34.20244598388672\n",
      "-----------------------\n",
      "Epoch:7/50 - train Loss:22.43526382446289\n",
      "Epoch:7/50 - test Loss:34.13270568847656\n",
      "-----------------------\n",
      "Epoch:8/50 - train Loss:21.58940544128418\n",
      "loss 32.95305633544922 -> 32.85969924926758 reduce saving ....\n",
      "Epoch:8/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:9/50 - train Loss:21.626192092895508\n",
      "Epoch:9/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:10/50 - train Loss:21.626192092895508\n",
      "Epoch:10/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:11/50 - train Loss:21.58940544128418\n",
      "Epoch:11/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:12/50 - train Loss:21.54860191345215\n",
      "Epoch:12/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:13/50 - train Loss:21.569003677368165\n",
      "Epoch:13/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:14/50 - train Loss:21.58940544128418\n",
      "Epoch:14/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:15/50 - train Loss:21.609807205200195\n",
      "Epoch:15/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:16/50 - train Loss:21.6506103515625\n",
      "Epoch:16/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:17/50 - train Loss:21.630208587646486\n",
      "Epoch:17/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:18/50 - train Loss:21.507798767089845\n",
      "Epoch:18/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:19/50 - train Loss:21.58940544128418\n",
      "Epoch:19/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:20/50 - train Loss:21.58940544128418\n",
      "Epoch:20/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:21/50 - train Loss:21.60980682373047\n",
      "Epoch:21/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:22/50 - train Loss:21.58940544128418\n",
      "Epoch:22/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:23/50 - train Loss:21.630208587646486\n",
      "Epoch:23/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:24/50 - train Loss:21.60980682373047\n",
      "Epoch:24/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:25/50 - train Loss:21.60980682373047\n",
      "Epoch:25/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:26/50 - train Loss:21.60980682373047\n",
      "Epoch:26/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:27/50 - train Loss:21.630208587646486\n",
      "Epoch:27/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:28/50 - train Loss:21.54860191345215\n",
      "Epoch:28/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:29/50 - train Loss:21.48739709854126\n",
      "Epoch:29/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:30/50 - train Loss:21.58940544128418\n",
      "Epoch:30/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:31/50 - train Loss:21.60980682373047\n",
      "Epoch:31/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:32/50 - train Loss:21.569003677368165\n",
      "Epoch:32/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:33/50 - train Loss:21.60980682373047\n",
      "Epoch:33/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:34/50 - train Loss:21.60980682373047\n",
      "Epoch:34/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:35/50 - train Loss:21.569003677368165\n",
      "Epoch:35/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:36/50 - train Loss:21.528200531005858\n",
      "Epoch:36/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:37/50 - train Loss:21.58940544128418\n",
      "Epoch:37/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:38/50 - train Loss:21.630208587646486\n",
      "Epoch:38/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:39/50 - train Loss:21.569003677368165\n",
      "Epoch:39/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:40/50 - train Loss:21.528200531005858\n",
      "Epoch:40/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:41/50 - train Loss:21.528200531005858\n",
      "Epoch:41/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:42/50 - train Loss:21.58940544128418\n",
      "Epoch:42/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:43/50 - train Loss:21.60980682373047\n",
      "Epoch:43/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:44/50 - train Loss:21.569003677368165\n",
      "Epoch:44/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:45/50 - train Loss:21.569003677368165\n",
      "Epoch:45/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:46/50 - train Loss:21.630208587646486\n",
      "Epoch:46/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:47/50 - train Loss:21.60980682373047\n",
      "Epoch:47/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:48/50 - train Loss:21.630208587646486\n",
      "Epoch:48/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Epoch:49/50 - train Loss:21.609807205200195\n",
      "Epoch:49/50 - test Loss:32.85969924926758\n",
      "-----------------------\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "# net = MRINet().to(device)\n",
    "net = model.to(device)\n",
    "LRate = 0.001\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = LRate)\n",
    "EPOCHS = 50\n",
    "best_score = np.inf\n",
    "\n",
    "\n",
    "best_model = copy.deepcopy(net)  # Will work\n",
    "    \n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    count = 0\n",
    "    net.train()\n",
    "    for indx, (data, label) in enumerate(train_loader, 0):\n",
    "        inputs, labels = data.to(device), label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs).squeeze(1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        total_loss += loss.detach().item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    print(f\"Epoch:{epoch}/{EPOCHS} - train Loss:{total_loss/count}\")\n",
    "    \n",
    "    net.eval()\n",
    "    total_loss = 0.0\n",
    "    count = 0\n",
    "    for indx, (data, label) in enumerate(test_loader, 0):\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = data.to(device), label.to(device)\n",
    "\n",
    "            outputs = net(inputs).squeeze(1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.detach().item()\n",
    "\n",
    "            count += 1\n",
    "    if best_score > total_loss / count:\n",
    "        print('loss {} -> {} reduce saving ....'.format(best_score, total_loss / count))\n",
    "        best_model = copy.deepcopy(net)  \n",
    "        \n",
    "        best_score = total_loss / count\n",
    "    print(f\"Epoch:{epoch}/{EPOCHS} - test Loss:{total_loss/count}\")\n",
    "    print('-----------------------')\n",
    "\n",
    "print(\"Training Complete\")    \n",
    "torch.save(best_model, './best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b6e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load('./best_model.pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3014046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "for indx, (data, label) in enumerate(test_loader, 0):\n",
    "    with torch.no_grad():\n",
    "        inputs, labels = data.to(device), label.to(device)\n",
    "        \n",
    "        outputs = net(inputs).squeeze(1)\n",
    "# outputs = torch.where(outputs > 0.00001, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0fb6832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7066e168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "        0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05051162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity:  1.0\n",
      "sensitivity:  0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(labels.int().cpu().numpy(), outputs.cpu().numpy()).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('specificity: ', specificity)\n",
    "print('sensitivity: ', sensitivity)\n",
    "# from sklearn.metrics import recall_score\n",
    "# recall_score(labels.int().cpu().numpy(), outputs.cpu().numpy(), pos_label = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a19177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd32eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c5784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
